# ğŸ’ğŸ…ğŸ“ Fruit Image Classification with CNNs (ResNetâ€‘50)

This project implements an **endâ€‘toâ€‘end deep learning pipeline** for image classification using **PyTorch**.  
The task: correctly identify whether an image contains a **cherry, tomato, or strawberry**.

It demonstrates the complete workflow of modern computer vision:
- **EDA & preprocessing**
- **Baselines** (MLP, custom CNN)
- **Transfer learning** with **ResNetâ€‘50** (final model)

> **Final model:** ResNetâ€‘50 (fineâ€‘tuned)  
> **Final test metrics:**  
> â€¢ Test Loss: **0.0775** Â· Overall Accuracy: **0.9765**  
> â€¢ Perâ€‘class Accuracy â€” Cherry: **0.9510** (466/490), Tomato: **0.9961** (505/507), Strawberry: **0.9818** (485/494)

---

## ğŸ¯ Objectives

- Build a complete **image classification pipeline** (EDA â†’ preprocessing â†’ training â†’ evaluation).  
- Compare architectures: **MLP**, **custom CNN**, **ResNetâ€‘50 transfer learning**.  
- Explore **augmentation**, **optimizers**, **losses**, **regularization**, and **crossâ€‘validation**.  
- Save, load, and evaluate trained models (`.pth`).

---

## ğŸ“Š Dataset

- **Total images:** 6,000 (RGB, ~300Ã—300) â€” **2,000 per class** (cherry, tomato, strawberry).  
- **Split:** 4,500 for training, 1,500 heldâ€‘out for testing.  
- **Source:** Images collected from **Flickr** (publicly available).  
- **Included:** Dataset is provided in this repo for reproducibility (respect Flickr terms).

**Normalization stats used (computed from training data):**
```python
mean = [0.5473, 0.4103, 0.3312]
std  = [0.2913, 0.2981, 0.2977]
```

---

## ğŸ—ï¸ Methodology

### 1) EDA
- Verified **class balance** (2,000 images per class).  
- Checked image sizes, outliers, and sample variability (scale, background, lighting).  
- Computed dataset **mean/std** for normalization.

### 2) Preprocessing & Augmentation
- **Resize:** 300Ã—300; **ToTensor**; **Normalize** with dataset stats.  
- **Augmentations:** random horizontal flip, rotation (Â±20Â°), random resized crop, color jitter.  
- **Stratified split** into train/validation to maintain class balance.

### 3) Models
- **Baseline MLP:** simple dense network (for nonâ€‘conv baseline).  
- **Custom CNN:** 3Ã—(Convâ†’ReLUâ†’Pool) + FC, with dropout.  
- **ResNetâ€‘50 (final):** preâ€‘trained on ImageNet; replaced final FC with 3â€‘class head and fineâ€‘tuned.

### 4) Training Setup
- **Loss:** CrossEntropyLoss (also experimented with **Focal Loss**).  
- **Optimizers:** Adam / SGD (momentum) / RMSprop; weight decay for regularization.  
- **Scheduler:** StepLR for LR decay on longer runs.  
- **Crossâ€‘Validation:** 5â€‘fold experiments for stability checks.  
- **Saving:** `torch.save(model.state_dict(), "model.pth")`; **Eval mode** used for testing.

### 5) Evaluation
- **Overall accuracy** + **perâ€‘class accuracy**.  
- **Learning curves** (loss/accuracy vs epochs) for train/val.  
- Sanity checks for data leakage/overfit; confusion trends reviewed qualitatively.

---

## ğŸ“ˆ Results

**Final Model:** ResNetâ€‘50 (fineâ€‘tuned)  
**Final Test Metrics:**
```
Test Loss: 0.0775, Overall Test Accuracy: 0.9765
Accuracy of cherry: 0.9510 (466/490)
Accuracy of tomato: 0.9961 (505/507)
Accuracy of strawberry: 0.9818 (485/494)
```

**Observations:**
- Loss steadily decreased with **augmentation + transfer learning**.  
- The **custom CNN** tended to overfit without strong augmentation; **ResNetâ€‘50** generalized better.

> ğŸ“· **Screenshots:**
> 
1. Sample dataset after augmentation
<p align="center">
  <img src="docs/augment.png" width="750">
</p>

2. Training vs Validation Loss for Resnet-50
<p align="center">
  <img src="docs/loss.png" width="500">
</p>

3. Training vs Validation Accuracy for Resnet-50
<p align="center">
  <img src="docs/accuracy.png" width="500">
</p>


```

---

## ğŸ“‚ Repository Structure

```text
.
â”œâ”€â”€ train.ipynb          # Training experiments (MLP, CNN, ResNetâ€‘50)
â”œâ”€â”€ test.py              # Script to evaluate saved model on images in testdata/
â”œâ”€â”€ model.pth            # Final trained ResNetâ€‘50 weights (Git LFS)
â”œâ”€â”€ traindata/           # Training dataset (Flickrâ€‘sourced)
â”œâ”€â”€ testdata/            # Example test images
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # This file
```

> â„¹ï¸ **Large files** are tracked via **Git LFS**. Ensure `git lfs install` before cloning/pulling.

---

## âš¡ How to Run

### 1) Install dependencies
```bash
pip install -r requirements.txt
```

### 2) Train (Jupyter)
```bash
jupyter notebook train.ipynb
```

### 3) Test (Saved model)
```bash
python test.py
```
This loads `model.pth`, evaluates on images in `./testdata/`, and prints overall + perâ€‘class accuracy.

---

## ğŸ¯ Where This Can Be Used

- **Agriculture:** crop/fruit identification, ripeness/quality inspection, disease screening.  
- **Retail:** automated produce checkout, inventory classification.  
- **Mobile Apps:** consumer education and field recognition tools.  
- **Education/Research:** CNNs vs transfer learning benchmarks and teaching demos.

---

## ğŸ§© Design Highlights

- Clear baseline â†’ advanced progression (**MLP â†’ CNN â†’ ResNetâ€‘50**).  
- Robust generalization via **augmentation**, **weight decay**, and **transfer learning**.  
- Reproducible results with **saved weights** and scripted evaluation.  
- Practical normalization derived from real training data stats.

---

## ğŸ“œ Attribution & Notes

- **Dataset:** Images collected from **Flickr**; resized to 300Ã—300.  
  - If you reuse beyond this project, please **respect Flickrâ€™s licensing/attribution requirements**.  
- **Model:** ResNetâ€‘50 from `torchvision.models` (preâ€‘trained on ImageNet).  
- **Code:** PyTorch, TorchVision, NumPy, Matplotlib, scikitâ€‘learn utilities.

---


